{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65FGAFndRwPS",
        "outputId": "d34772c7-c621-451e-a055-ee501346db5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "from nltk import pos_tag, word_tokenize, RegexpParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "y5yh2XUVRwPW"
      },
      "outputs": [],
      "source": [
        "sample_text = \"The quick brown fox jumps over the lazy dog\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b2KaTm5ORwPW"
      },
      "outputs": [],
      "source": [
        "tagged = pos_tag(word_tokenize(sample_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-2a02B8RwPX",
        "outputId": "644d2326-61a7-457c-fdc0-cbb3b81f0b82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('quick', 'JJ'),\n",
              " ('brown', 'NN'),\n",
              " ('fox', 'NN'),\n",
              " ('jumps', 'VBZ'),\n",
              " ('over', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('lazy', 'JJ'),\n",
              " ('dog', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FOqXJTsgRwPX"
      },
      "outputs": [],
      "source": [
        "#Extract all parts of speech from any text\n",
        "chunker = RegexpParser(\"\"\"\n",
        "NP: {<DT>?<JJ>*<NN>} #To extract Noun Phrases\n",
        "P: {<IN>} #To extract Prepositions\n",
        "V: {<V.*>} #To extract Verbs\n",
        "PP: {<P> <NP>} #To extract Prepostional Phrases\n",
        "VP: {<V> <NP|PP>*} #To extarct Verb Phrases\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sC7bm4YRwPX",
        "outputId": "96dd8fbe-a1e7-4340-fa0b-52ec3e334e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Extracting\n",
            " (S\n",
            "  (NP The/DT quick/JJ brown/NN)\n",
            "  (NP fox/NN)\n",
            "  (VP (V jumps/VBZ) (PP (P over/IN) (NP the/DT lazy/JJ dog/NN))))\n"
          ]
        }
      ],
      "source": [
        "output = chunker.parse(tagged)\n",
        "print(\"After Extracting\\n\", output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW5N-QhbRwPY",
        "outputId": "f32e4908-b2a1-4b73-dca6-8c15f1c27462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP The/DT quick/JJ brown/NN)\n",
            "  (NP fox/NN)\n",
            "  (VP (V jumps/VBZ) (PP (P over/IN) (NP the/DT lazy/JJ dog/NN))))\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "X6FRVfLuRwPY"
      },
      "outputs": [],
      "source": [
        "# Example text\n",
        "#sample_text = \"The quick brown fox jumps over the lazy dog\"\n",
        "sample_text = \"Съешь ещё этих мягких французских булок, да выпей чаю\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIZwqhm2RwPY",
        "outputId": "b0238443-4cac-4955-e893-1bba6dbd2b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_rus.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_rus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phZeFDuiRwPZ",
        "outputId": "aefef364-9d77-4038-f764-8ed14ee54177"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Съешь', 'V'),\n",
              " ('ещё', 'ADV'),\n",
              " ('этих', 'A-PRO=pl'),\n",
              " ('мягких', 'A=pl'),\n",
              " ('французских', 'A=pl'),\n",
              " ('булок', 'S'),\n",
              " (',', 'NONLEX'),\n",
              " ('да', 'CONJ'),\n",
              " ('выпей', 'V'),\n",
              " ('чаю', 'S')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Find all parts of speech in above sentence\n",
        "tagged = pos_tag(word_tokenize(sample_text), lang='rus')\n",
        "tagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAB82BCFRwPZ",
        "outputId": "0aa638bd-d719-44f9-adfb-c59b42f21e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Extracting\n",
            " (S\n",
            "  (VP (V Съешь/V))\n",
            "  ещё/ADV\n",
            "  этих/A-PRO=pl\n",
            "  мягких/A=pl\n",
            "  французских/A=pl\n",
            "  булок/S\n",
            "  ,/NONLEX\n",
            "  да/CONJ\n",
            "  (VP (V выпей/V))\n",
            "  чаю/S)\n"
          ]
        }
      ],
      "source": [
        "output = chunker.parse(tagged)\n",
        "print(\"After Extracting\\n\", output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKPRduiYRwPZ",
        "outputId": "b992d656-af64-4d81-cf81-5d56eb93701e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (VP (V Съешь/V))\n",
            "  ещё/ADV\n",
            "  этих/A-PRO=pl\n",
            "  мягких/A=pl\n",
            "  французских/A=pl\n",
            "  булок/S\n",
            "  ,/NONLEX\n",
            "  да/CONJ\n",
            "  (VP (V выпей/V))\n",
            "  чаю/S)\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-8zGFRiwRwPZ"
      },
      "outputs": [],
      "source": [
        "chunker = RegexpParser(\"\"\"\n",
        "NP: {<A>*<S>} #To extract Noun Phrases\n",
        "P: {<PR>} #To extract Prepositions\n",
        "V: {<V.*>} #To extract Verbs\n",
        "PP: {<P> <NP>} #To extract Prepostional Phrases\n",
        "VP: {<V> <NP|PP>*} #To extarct Verb Phrases\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}