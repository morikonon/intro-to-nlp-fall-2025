{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cP0yLWkoD58H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FEGQoybbD58J"
      },
      "outputs": [],
      "source": [
        "text = ['Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them',\n",
        "'So when they were old enough, she sent them out into the world to seek their fortunes.',\n",
        "'The first little pig was very lazy',\n",
        "\"He didn't want to work at all and he built his house out of straw\",\n",
        "'The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks',\n",
        "'Then, they sang and danced and played together the rest of the day.',\n",
        "'The third little pig worked hard all day and built his house with bricks',\n",
        "'It was a sturdy house complete with a fine fireplace and chimney',\n",
        "'It looked like it could withstand the strongest winds.',\n",
        "'The next day, a wolf happened to pass by the lane where the three little pigs lived; and he saw the straw house, and he smelled the pig inside',\n",
        "'He thought the pig would make a mighty fine meal and his mouth began to water.',\n",
        "'So he knocked on the door and said:',\n",
        "' Little pig! Little pig!',\n",
        "' Let me in! Let me in!',\n",
        "\"But the little pig saw the wolf's big paws through the keyhole, so he answered back:\",\n",
        "' No! No! No! ',\n",
        "' Not by the hairs on my chinny chin chin!',\n",
        "'Then the wolf showed his teeth and said:',\n",
        "\" Then I'll huff \",\n",
        "\" and I'll puff \",\n",
        "\" and I'll blow your house down.\",\n",
        "'So he huffed and he puffed and he blew the house down! The wolf opened his jaws very wide and bit down as hard as he could, but the first little pig escaped and ran away to hide with the second little pig.',\n",
        "'The wolf continued down the lane and he passed by the second house made of sticks; and he saw the house, and he smelled the pigs inside, and his mouth began to water as he thought about the fine dinner they would make.',\n",
        "'So he knocked on the door and said:',\n",
        "' Little pigs! Little pigs!',\n",
        "' Let me in! Let me in!',\n",
        "\"But the little pigs saw the wolf's pointy ears through the keyhole, so they answered back:\",\n",
        "' No! No! No!',\n",
        "' Not by the hairs on our chinny chin chin!',\n",
        "'So the wolf showed his teeth and said:',\n",
        "\" Then I'll huff \",\n",
        "\" and I'll puff \",\n",
        "\" and I'll blow your house down!\",\n",
        "'So he huffed and he puffed and he blew the house down! The wolf was greedy and he tried to catch both pigs at once, but he was too greedy and got neither! His big jaws clamped down on nothing but air and the two little pigs scrambled away as fast as their little hooves would carry them.',\n",
        "'The wolf chased them down the lane and he almost caught them',\n",
        "'But they made it to the brick house and slammed the door closed before the wolf could catch them',\n",
        "'The three little pigs they were very frightened, they knew the wolf wanted to eat them',\n",
        "'And that was very, very true',\n",
        "\"The wolf hadn't eaten all day and he had worked up a large appetite chasing the pigs around and now he could smell all three of them inside and he knew that the three little pigs would make a lovely feast.\",\n",
        "'So the wolf knocked on the door and said:',\n",
        "' Little pigs! Little pigs!',\n",
        "' Let me in! Let me in!',\n",
        "\"But the little pigs saw the wolf's narrow eyes through the keyhole, so they answered back:\",\n",
        "' No! No! No! ',\n",
        "' Not by the hairs on our chinny chin chin!',\n",
        "'So the wolf showed his teeth and said:',\n",
        "\" Then I'll huff \",\n",
        "\" and I'll puff \",\n",
        "\" and I'll blow your house down.\",\n",
        "'Well! he huffed and he puffed',\n",
        "'He puffed and he huffed',\n",
        "'And he huffed, huffed, and he puffed, puffed; but he could not blow the house down',\n",
        "\"At last, he was so out of breath that he couldn't huff and he couldn't puff anymore\",\n",
        "'So he stopped to rest and thought a bit.',\n",
        "'But this was too much',\n",
        "'The wolf danced about with rage and swore he would come down the chimney and eat up the little pig for his supper',\n",
        "'But while he was climbing on to the roof the little pig made up a blazing fire and put on a big pot full of water to boil',\n",
        "'Then, just as the wolf was coming down the chimney, the little piggy pulled off the lid, and plop! in fell the wolf into the scalding water.',\n",
        "'So the little piggy put on the cover again, boiled the wolf up, and the three little pigs ate him for supper.']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IoXWxpodD58K"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "2wWYv-F1D58K",
        "outputId": "a788bc47-34a4-4427-ceb4-8ecc3af07b54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nNumber  Tag  Description\\n1.\\tCC\\tCoordinating conjunction\\n2.\\tCD\\tCardinal number\\n3.\\tDT\\tDeterminer\\n4.\\tEX\\tExistential there\\n5.\\tFW\\tForeign word\\n6.\\tIN\\tPreposition or subordinating conjunction\\n7.\\tJJ\\tAdjective\\n8.\\tJJR\\tAdjective, comparative\\n9.\\tJJS\\tAdjective, superlative\\n10.\\tLS\\tList item marker\\n11.\\tMD\\tModal\\n12.\\tNN\\tNoun, singular or mass\\n13.\\tNNS\\tNoun, plural\\n14.\\tNNP\\tProper noun, singular\\n15.\\tNNPS\\tProper noun, plural\\n16.\\tPDT\\tPredeterminer\\n17.\\tPOS\\tPossessive ending\\n18.\\tPRP\\tPersonal pronoun\\n19.\\tPRP$\\tPossessive pronoun\\n20.\\tRB\\tAdverb\\n21.\\tRBR\\tAdverb, comparative\\n22.\\tRBS\\tAdverb, superlative\\n23.\\tRP\\tParticle\\n24.\\tSYM\\tSymbol\\n25.\\tTO\\tto\\n26.\\tUH\\tInterjection\\n27.\\tVB\\tVerb, base form\\n28.\\tVBD\\tVerb, past tense\\n29.\\tVBG\\tVerb, gerund or present participle\\n30.\\tVBN\\tVerb, past participle\\n31.\\tVBP\\tVerb, non-3rd person singular present\\n32.\\tVBZ\\tVerb, 3rd person singular present\\n33.\\tWDT\\tWh-determiner\\n34.\\tWP\\tWh-pronoun\\n35.\\tWP$\\tPossessive wh-pronoun\\n36.\\tWRB\\tWh-adverb\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "'''\n",
        "\n",
        "Number  Tag  Description\n",
        "1.\tCC\tCoordinating conjunction\n",
        "2.\tCD\tCardinal number\n",
        "3.\tDT\tDeterminer\n",
        "4.\tEX\tExistential there\n",
        "5.\tFW\tForeign word\n",
        "6.\tIN\tPreposition or subordinating conjunction\n",
        "7.\tJJ\tAdjective\n",
        "8.\tJJR\tAdjective, comparative\n",
        "9.\tJJS\tAdjective, superlative\n",
        "10.\tLS\tList item marker\n",
        "11.\tMD\tModal\n",
        "12.\tNN\tNoun, singular or mass\n",
        "13.\tNNS\tNoun, plural\n",
        "14.\tNNP\tProper noun, singular\n",
        "15.\tNNPS\tProper noun, plural\n",
        "16.\tPDT\tPredeterminer\n",
        "17.\tPOS\tPossessive ending\n",
        "18.\tPRP\tPersonal pronoun\n",
        "19.\tPRP$\tPossessive pronoun\n",
        "20.\tRB\tAdverb\n",
        "21.\tRBR\tAdverb, comparative\n",
        "22.\tRBS\tAdverb, superlative\n",
        "23.\tRP\tParticle\n",
        "24.\tSYM\tSymbol\n",
        "25.\tTO\tto\n",
        "26.\tUH\tInterjection\n",
        "27.\tVB\tVerb, base form\n",
        "28.\tVBD\tVerb, past tense\n",
        "29.\tVBG\tVerb, gerund or present participle\n",
        "30.\tVBN\tVerb, past participle\n",
        "31.\tVBP\tVerb, non-3rd person singular present\n",
        "32.\tVBZ\tVerb, 3rd person singular present\n",
        "33.\tWDT\tWh-determiner\n",
        "34.\tWP\tWh-pronoun\n",
        "35.\tWP$\tPossessive wh-pronoun\n",
        "36.\tWRB\tWh-adverb\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pNxgx1iD58L",
        "outputId": "3a9e94de-5bb0-4073-e535-1b17c7a9717a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uZKsMYrD58L"
      },
      "source": [
        "**A POS tag means Part-of-Speech tag. It’s a label that tells you the grammatical role of a word in a sentence**\n",
        "\n",
        "For example:\n",
        "\n",
        "Noun (NN) – person, place, thing (e.g., dog, car, idea)\n",
        "\n",
        "Verb (VB) – action or state (e.g., run, is, think)\n",
        "\n",
        "Adjective (JJ) – describes a noun (e.g., happy, big, red)\n",
        "\n",
        "Adverb (RB) – describes a verb/adjective (e.g., quickly, very)\n",
        "\n",
        "Pronoun (PRP) – replaces a noun (e.g., he, she, it)\n",
        "\n",
        "Determiner (DT) – introduces a noun (e.g., the, a, this)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = [\"My name is Mukhamedali, I am 19 years old\"]"
      ],
      "metadata": {
        "id": "EHLv7MRKEeFi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in sample_text:\n",
        "  print(text.split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEIH8N7OFQs1",
        "outputId": "254df20a-a98e-48ed-fa8a-f3573e3d0713"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'name', 'is', 'Mukhamedali,', 'I', 'am', '19', 'years', 'old']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_pos_tagged_text = [nltk.pos_tag(text.split(' ')) for text in sample_text]\n",
        "sample_pos_tagged_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OydR5BvQEiiq",
        "outputId": "6639f600-fb3c-46aa-9d35-7db937b344ba"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('My', 'PRP$'),\n",
              "  ('name', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('Mukhamedali,', 'NNP'),\n",
              "  ('I', 'PRP'),\n",
              "  ('am', 'VBP'),\n",
              "  ('19', 'CD'),\n",
              "  ('years', 'NNS'),\n",
              "  ('old', 'JJ')]]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vSGu8zbD58M",
        "outputId": "ccaf36c8-5dce-4e9d-ccd3-da91528d454d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('M', 'NN')],\n",
              " [('y', 'NN')],\n",
              " [('', 'NN')],\n",
              " [('n', 'NN')],\n",
              " [('a', 'DT')],\n",
              " [('m', 'NN')],\n",
              " [('e', 'NN')],\n",
              " [('', 'NN')],\n",
              " [('i', 'NN')],\n",
              " [('s', 'NN')],\n",
              " [('', 'NN')],\n",
              " [('M', 'NN')],\n",
              " [('u', 'NN')],\n",
              " [('k', 'NN')],\n",
              " [('h', 'NN')],\n",
              " [('a', 'DT')],\n",
              " [('m', 'NN')],\n",
              " [('e', 'NN')],\n",
              " [('d', 'NN')],\n",
              " [('a', 'DT')],\n",
              " [('l', 'NN')],\n",
              " [('i', 'NN')],\n",
              " [(',', ',')],\n",
              " [('', 'NN')],\n",
              " [('I', 'PRP')],\n",
              " [('', 'NN')],\n",
              " [('a', 'DT')],\n",
              " [('m', 'NN')],\n",
              " [('', 'NN')],\n",
              " [('1', 'CD')],\n",
              " [('9', 'CD')],\n",
              " [('', 'NN')],\n",
              " [('y', 'NN')],\n",
              " [('e', 'NN')],\n",
              " [('a', 'DT')],\n",
              " [('r', 'NN')],\n",
              " [('s', 'NN')],\n",
              " [('', 'NN')],\n",
              " [('o', 'NN')],\n",
              " [('l', 'NN')],\n",
              " [('d', 'NN')]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "pos_tagged_text=[nltk.pos_tag(text[i].strip().split(' ')) for i in range(len(text))]\n",
        "pos_tagged_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jTFnkMmD58M"
      },
      "source": [
        "# Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8yRo2b1jD58N"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9zW4scHD58N",
        "outputId": "393b756e-8498-4ce6-a9cc-b1f62a42697a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')  # иногда требуется для мультиязычной поддержки\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pEBoEisrD58N"
      },
      "outputs": [],
      "source": [
        "def get_pos_tag(t):\n",
        "    try:\n",
        "        tag_dict = {\"J\": wordnet.ADJ,\n",
        "        \"N\": wordnet.NOUN,\n",
        "        \"V\": wordnet.VERB,\n",
        "        \"R\": wordnet.ADV,\n",
        "        \"P\": wordnet.NOUN,#\n",
        "        \"C\": wordnet.NOUN,\n",
        "        \"D\": wordnet.NOUN,\n",
        "        \"E\": wordnet.NOUN,\n",
        "        \"I\": wordnet.NOUN,\n",
        "        \"L\": wordnet.NOUN,\n",
        "        \"M\": wordnet.NOUN,\n",
        "        \"T\": wordnet.NOUN,\n",
        "        \"U\": wordnet.NOUN,\n",
        "        \"W\": wordnet.NOUN,\n",
        "        \"F\": wordnet.NOUN,\n",
        "        \"S\": wordnet.NOUN}\n",
        "        return tag_dict[t[0]]\n",
        "    except:\n",
        "        return wordnet.NOUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "YQWyj0idD58N",
        "outputId": "b723c08d-af77-4796-b2dc-4194d3a476a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "get_pos_tag('reading')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4qyi-gVD58O",
        "outputId": "97041a5d-8146-44fb-9c36-278d0a75fbdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'), ('read', 'VBP')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "nltk.pos_tag(['I','read'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "e0MzX0xeD58O"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_text = [' '.join([lemmatizer.lemmatize(tg[0], pos=get_pos_tag(tg[1]))\n",
        "for tg in nltk.pos_tag(s.strip().split(' '))])\n",
        "for s in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07zkLhgSD58O",
        "outputId": "789c2910-29ee-4261-a5fb-0d1e7b0eb5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My na\n",
            "['M', 'y', '', 'n', 'a']\n"
          ]
        }
      ],
      "source": [
        "print(text[:5])\n",
        "print(lemmatized_text[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bqhU4pfD58O"
      },
      "source": [
        "# Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "J4QqSxynD58O"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knr_AZPyD58P",
        "outputId": "dd6399b0-9e1c-4bf7-ff20-7142d5be83ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['m'], ['y'], [], ['n'], ['a']]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "ps = PorterStemmer()\n",
        "stemmed_text=[[ps.stem(w) for w in s.strip().split()] for s in text]\n",
        "stemmed_text[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToN0uuDqD58P"
      },
      "source": [
        "# Write your own algorithms for Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xm3O3SfJqsf",
        "outputId": "9a0beec4-c97c-4664-f636-faee3c7d4636"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"The cats were playing happily, chasing the mice's tails, and learned many new things.\""
      ],
      "metadata": {
        "id": "VHq-6KizKFI0"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag([\"Name\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAsSnU29PxIz",
        "outputId": "1d087839-0e08-4df3-c5cb-a4f1230192a2"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "oMWzixI9D58P"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "\n",
        "def get_wordnet_pos(word_pos):\n",
        "  if word_pos.startswith(\"J\"):\n",
        "    return wordnet.ADJ\n",
        "  elif word_pos.startswith(\"V\"):\n",
        "    return wordnet.VERB\n",
        "  elif word_pos.startswith(\"N\"):\n",
        "    return wordnet.NOUN\n",
        "  elif word_pos.startswith(\"R\"):\n",
        "    return wordnet.ADV\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "# это функция с использованием nltk\n",
        "def lemmatize_function(text):\n",
        "  # переводим текст в токены\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "\n",
        "  # получем типы речи\n",
        "  tagged_tokens = nltk.pos_tag(tokens)\n",
        "\n",
        "  # массив для хранение токенов\n",
        "  lemmatized_tokens = []\n",
        "\n",
        "  # пробегаемся по tagged_tokens\n",
        "  for word, tag in tagged_tokens:\n",
        "    # узнаем и получем его типо речи\n",
        "    wntag = get_wordnet_pos(tag)\n",
        "\n",
        "    # если знаем тип речи то по нему и лемматизируем\n",
        "    if wntag:\n",
        "      lemmatized_token = lemmatizer.lemmatize(word, wntag)\n",
        "\n",
        "    # если не знаем то просто лемматизируем по 'noun'\n",
        "    else:\n",
        "      lemmatized_token = lemmatizer.lemmatize(word)\n",
        "\n",
        "    lemmatized_tokens.append(lemmatized_token)\n",
        "\n",
        "  return tokens, lemmatized_tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens, lemmatized_tokens = lemmatize_function(sample_text)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAkN3SiwQFXj",
        "outputId": "f22d13f5-be9f-4daf-e3ec-496f22acd8a5"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'cats',\n",
              " 'were',\n",
              " 'playing',\n",
              " 'happily',\n",
              " ',',\n",
              " 'chasing',\n",
              " 'the',\n",
              " 'mice',\n",
              " \"'s\",\n",
              " 'tails',\n",
              " ',',\n",
              " 'and',\n",
              " 'learned',\n",
              " 'many',\n",
              " 'new',\n",
              " 'things',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtv2vr3GKIaZ",
        "outputId": "8c6d6e67-9275-4cbf-de19-9ca7e826401a"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'cat',\n",
              " 'be',\n",
              " 'play',\n",
              " 'happily',\n",
              " ',',\n",
              " 'chase',\n",
              " 'the',\n",
              " 'mouse',\n",
              " \"'s\",\n",
              " 'tail',\n",
              " ',',\n",
              " 'and',\n",
              " 'learn',\n",
              " 'many',\n",
              " 'new',\n",
              " 'thing',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# функция лемматизации без nltk\n",
        "words_to_delete = [\"ment\", \"tion\", \"ing\", \"est\", \"ion\", \"ed\", \"es\", \"ly\", \"er\", \"'s\", \"s\"]\n",
        "\n",
        "def lemmatize(text):\n",
        "  # переводим текст в токены\n",
        "  tokens = text.strip(',').split(' ')\n",
        "\n",
        "  # функция которая хранит токены после лемматизации\n",
        "  lemmatized_tokens = []\n",
        "\n",
        "  # пробегаемся по массиву\n",
        "  for token in tokens:\n",
        "    lemmatized_token = token\n",
        "    lemmatized = False\n",
        "\n",
        "    # пробегаемся по словам которые мы должны удалить в оконачании\n",
        "    for word_to_delete in words_to_delete:\n",
        "      if lemmatized_token.endswith(word_to_delete):\n",
        "\n",
        "        # удаляем окончание\n",
        "        lemmatized_token = lemmatized_token[:-len(word_to_delete)]\n",
        "\n",
        "        # после окончание сразу же делаем break\n",
        "        lemmatized = True\n",
        "        break\n",
        "\n",
        "    # сохраняем токен который лемматизирован\n",
        "    lemmatized_tokens.append(lemmatized_token)\n",
        "\n",
        "  return tokens, lemmatized_tokens"
      ],
      "metadata": {
        "id": "jG5cgkXMLd7b"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens , lemmatized_tokens = lemmatize(sample_text)"
      ],
      "metadata": {
        "id": "6Qh4h_nMLqgm"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_7cjt3SMf6E",
        "outputId": "0f6eaa99-380c-408c-ff14-f897a2abedd1"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'cats',\n",
              " 'were',\n",
              " 'playing',\n",
              " 'happily,',\n",
              " 'chasing',\n",
              " 'the',\n",
              " \"mice's\",\n",
              " 'tails,',\n",
              " 'and',\n",
              " 'learned',\n",
              " 'many',\n",
              " 'new',\n",
              " 'things.']"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUg6BeQyMgup",
        "outputId": "fb6acb8b-7b09-4066-8e26-e005d2129091"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'cat',\n",
              " 'were',\n",
              " 'play',\n",
              " 'happily,',\n",
              " 'chas',\n",
              " 'the',\n",
              " 'mice',\n",
              " 'tails,',\n",
              " 'and',\n",
              " 'learn',\n",
              " 'many',\n",
              " 'new',\n",
              " 'things.']"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}